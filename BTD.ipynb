{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad297d4-82fe-41c6-9aaf-16445ced493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: {'glioma_tumor': 826, 'meningioma_tumor': 822, 'pituitary_tumor': 827, 'no_tumor': 395}\n",
      "Found 2870 images belonging to 4 classes.\n",
      "Found 394 images belonging to 4 classes.\n",
      "Class Weights: {0: 0.8686440677966102, 1: 0.8728710462287105, 2: 1.8164556962025316, 3: 0.8675937122128174}\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2us/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91808\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5903 - loss: 1.4340 - val_accuracy: 0.5838 - val_loss: 1.5168 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 650ms/step - accuracy: 0.7829 - loss: 0.5363 - val_accuracy: 0.6168 - val_loss: 1.5622 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 671ms/step - accuracy: 0.8106 - loss: 0.4560 - val_accuracy: 0.6168 - val_loss: 1.5407 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 714ms/step - accuracy: 0.8387 - loss: 0.3988 - val_accuracy: 0.6497 - val_loss: 1.4432 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 787ms/step - accuracy: 0.8363 - loss: 0.3894 - val_accuracy: 0.6218 - val_loss: 1.6179 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 697ms/step - accuracy: 0.8624 - loss: 0.3125 - val_accuracy: 0.6548 - val_loss: 1.8454 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 627ms/step - accuracy: 0.8541 - loss: 0.3397 - val_accuracy: 0.6117 - val_loss: 1.7021 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 694ms/step - accuracy: 0.8705 - loss: 0.3121 - val_accuracy: 0.6751 - val_loss: 1.6134 - learning_rate: 5.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 698ms/step - accuracy: 0.8897 - loss: 0.2876 - val_accuracy: 0.6777 - val_loss: 1.6066 - learning_rate: 5.0000e-05\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 523ms/step - accuracy: 0.6692 - loss: 1.4561\n",
      "Validation Loss: 1.5806158781051636, Validation Accuracy: 0.6700507402420044\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 97\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# 10. Sample Augmentation Visualization\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m sample_batch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m()\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     99\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(sample_batch[\u001b[38;5;241m0\u001b[39m][i])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Set paths and parameters\n",
    "data_dir = r'C:\\Users\\91808\\Desktop\\PROJECT 7th sem\\brain_tumor_dataset\\Training'  # For training data\n",
    "validation_dir = r'C:\\Users\\91808\\Desktop\\PROJECT 7th sem\\brain_tumor_dataset\\Testing'  # For testing/validation data\n",
    "classes = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'no_tumor']\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# 1. Count Images in Each Class (Label Distribution)\n",
    "label_counts = {label: len(os.listdir(os.path.join(data_dir, label))) for label in classes}\n",
    "print(\"Label Counts:\", label_counts)\n",
    "\n",
    "# 2. Data Augmentation and Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    validation_split=0.15  # Reserve 15% for validation\n",
    ")\n",
    "\n",
    "# 3. Data Generators for Training and Validation\n",
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Compute Class Weights for Handling Imbalance\n",
    "y_train = train_generator.classes\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(\"Class Weights:\", class_weights_dict)\n",
    "\n",
    "# 5. Model Architecture with Transfer Learning (MobileNetV2)\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze base model layers\n",
    "\n",
    "# Add custom layers for our specific classification task\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')  # Four output classes\n",
    "])\n",
    "\n",
    "# 6. Compile the Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss=CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 7. Set Callbacks for Early Stopping and Learning Rate Reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# 8. Train the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=50,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# 9. Evaluate the Model on Validation Set\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# 10. Sample Augmentation Visualization\n",
    "sample_batch = train_generator.next()\n",
    "for i in range(5):\n",
    "    plt.imshow(sample_batch[0][i])\n",
    "    plt.title(f\"Class: {np.argmax(sample_batch[1][i])}\")\n",
    "    plt.show()\n",
    "\n",
    "# 11. Plot Training History\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
